{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Exercise (Chapter 7 & 8)\n",
    "This exercise focuses on optimization and regularization.\n",
    "\n",
    "In the optimization part, we will\n",
    "- implement the Adam optimizer\n",
    "- compare Adam, SGD, SGD with Momentum\n",
    "- implement and analyze some learning rate schedules\n",
    "\n",
    "In the regularization part, we will\n",
    "- implement Dropout\n",
    "- implement L1/L2 loss\n",
    "- analyze the effect of the different regularization methods on the parameter distribution.\n",
    "- think about early stopping and data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **reuse the code you wrote in the last exercise, or you can use the code we provide (below)**. Just copy the relevant parts into the cell below. Please **note that we extended the `Module` class** with a state to determine whether we're training or evaluating and two functions to toggle this state. We therefore also adapted the training loop function.\n",
    "\n",
    "The first task of this exercise is to implement Adam, you can **skip forward to the exercises by clicking [here](#adam)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classes: `Parameter` and `Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Optional, Tuple, Callable\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    \"\"\"A trainable parameter.\n",
    "\n",
    "    This class not only stores th_solution-Copy1e value of the parameter but also tensors/\n",
    "    properties associated with it, such as the gradient of the current backward\n",
    "    pass.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: np.ndarray, name: Optional[str] = None):\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "        self.name = name\n",
    "        self.state_dict = dict()  # dict to store additional, optional information\n",
    "\n",
    "\n",
    "class Module:\n",
    "    \"\"\"The base class all network modules must inherit from.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Cache of the input of the forward pass.\n",
    "        # We need it during the backward pass in most layers,\n",
    "        #  e.g., to compute the gradient w.r.t to the weights.\n",
    "        self.input_cache = None\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, *args) -> np.ndarray:\n",
    "        \"\"\"Alias for forward, convenience function.\"\"\"\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def forward(self, *args) -> np.ndarray:\n",
    "        \"\"\"Compute the forward pass through the module.\n",
    "\n",
    "        Args:\n",
    "           args: The inputs, e.g., the output of the previous layer.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute the backward pass through the module.\n",
    "\n",
    "        This method computes the gradients with respect to the trainable\n",
    "        parameters and with respect to the first input.\n",
    "        If the module has trainable parameters, this method needs to update\n",
    "        the respective parameter.grad property.\n",
    "\n",
    "        Args:\n",
    "            grad: The gradient of the following layer.\n",
    "\n",
    "        Returns:\n",
    "            The gradient with respect to the first input argument. In general\n",
    "            it might be useful to return the gradients w.r.t. to all inputs, we\n",
    "            omit this here to keep things simple.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        \"\"\"Return the module parameters.\"\"\"\n",
    "        return []  # default to empty list\n",
    "\n",
    "    def train(self, mode : bool = True) -> 'Module':\n",
    "        \"\"\"Set the module to training mode.\n",
    "\n",
    "        This only affects some Modules, such as Dropout.\n",
    "        \n",
    "        Returns:\n",
    "            self.\n",
    "        \"\"\"\n",
    "        self.training = mode\n",
    "        return self\n",
    "\n",
    "    def eval(self) -> 'Module':\n",
    "        \"\"\"Set the module to evaluation mode.\n",
    "\n",
    "        This only affects some Modules, such as Dropout.\n",
    "\n",
    "        Returns:\n",
    "            self.\n",
    "        \"\"\"\n",
    "        return self.train(False)\n",
    "\n",
    "    def check_gradients(self, input_args: Tuple[np.ndarray]):\n",
    "        \"\"\"Verify the implementation of the gradients.\n",
    "\n",
    "        This includes the gradient with respect to the input as well as the\n",
    "        gradients w.r.t. the parameters if the module contains any.\n",
    "\n",
    "        As the scipy grad check only works on scalar functions, we compute\n",
    "        the sum over the output to obtain a scalar.\n",
    "        \"\"\"\n",
    "        assert isinstance(input_args, tuple), (\n",
    "            \"input_args must be a tuple but is {}\".format(type(input_args)))\n",
    "        TOLERANCE = 1e-6\n",
    "        self.check_gradients_wrt_input(input_args, TOLERANCE)\n",
    "        self.check_gradients_wrt_params(input_args, TOLERANCE)\n",
    "\n",
    "    def _zero_grad(self):\n",
    "        \"\"\"(Re-) intialize the param's grads to 0. Helper for grad checking.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.grad = np.zeros_like(p.data)\n",
    "\n",
    "    def check_gradients_wrt_input(self, input_args: Tuple[np.ndarray],\n",
    "                                  tolerance: float):\n",
    "        \"\"\"Verify the implementation of the module's gradient w.r.t. input.\"\"\"\n",
    "\n",
    "        def output_given_input(x: np.ndarray):\n",
    "            \"\"\"Wrap self.forward for scipy.optimize.check_grad.\"\"\"\n",
    "            # we only compute the gradient w.r.t. to the first input arg.\n",
    "            args = (x.reshape(input_args[0].shape),) + input_args[1:]\n",
    "            return np.sum(self.forward(*args))\n",
    "\n",
    "        def grad_given_input(x: np.ndarray):\n",
    "            \"\"\"Wrap self.backward for scipy.optimize.check_grad.\"\"\"\n",
    "            self._zero_grad()\n",
    "            # run self.forward to store the new input\n",
    "            args = (x.reshape(input_args[0].shape),) + input_args[1:]\n",
    "            out = self.forward(*args)\n",
    "            # compute the gradient w.r.t. to the input\n",
    "            return np.ravel(self.backward(np.ones_like(out)))\n",
    "\n",
    "        error = scipy.optimize.check_grad(\n",
    "            output_given_input, grad_given_input, np.ravel(input_args[0]))\n",
    "        num_outputs = np.prod(self.forward(*input_args).shape)\n",
    "        if np.squeeze(error) / num_outputs > tolerance:\n",
    "            raise RuntimeError(\"Check of gradient w.r.t. to input for {} failed.\"\n",
    "                               \"Error {:.4E} > {:.4E}.\"\n",
    "                               .format(self, np.squeeze(error), tolerance))\n",
    "\n",
    "    def check_gradients_wrt_params(self, input_args: Tuple[np.ndarray],\n",
    "                                   tolerance: float):\n",
    "        \"\"\"Verify the implementation of the module's gradient w.r.t. params.\"\"\"\n",
    "        for param in self.parameters():\n",
    "            def output_given_params(new_param: np.ndarray):\n",
    "                \"\"\"Wrap self.forward, change the parameters to new_param.\"\"\"\n",
    "                param.data = new_param.reshape(param.data.shape)\n",
    "                return np.sum(self.forward(*input_args))\n",
    "\n",
    "            def grad_given_params(new_param: np.ndarray):\n",
    "                self._zero_grad()\n",
    "                param.data = new_param.reshape(param.data.shape)\n",
    "                out = self.forward(*input_args)\n",
    "                # compute the gradient w.r.t. to param\n",
    "                self.backward(np.ones_like(out))\n",
    "                return np.ravel(param.grad)\n",
    "            # flatten the param as scipy can only handle 1D params\n",
    "            param_init = np.ravel(np.copy(param.data))\n",
    "            error = scipy.optimize.check_grad(output_given_params,\n",
    "                                              grad_given_params,\n",
    "                                              param_init)\n",
    "            num_outputs = np.prod(self.forward(*input_args).shape)\n",
    "            if np.squeeze(error) / num_outputs > tolerance:\n",
    "                raise RuntimeError(\"Check of gradient w.r.t. to param '{}' for\"\n",
    "                                   \"{} failed. Error {:.4E} > {:.4E}.\"\n",
    "                                   .format(param.name, self, error, tolerance))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions: `Relu` and `Softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Module):\n",
    "\n",
    "    def forward(self, z: np.ndarray) -> np.ndarray:\n",
    "        # Shift input for numerical stability.\n",
    "        reduction_axes = tuple(range(1, len(z.shape)))\n",
    "        shift_z = z - np.max(z, axis=reduction_axes, keepdims=True)\n",
    "        exps = np.exp(shift_z)\n",
    "        h = exps / np.sum(exps, axis=reduction_axes, keepdims=True)\n",
    "        return h\n",
    "\n",
    "    def backward(self, grad) -> np.ndarray:\n",
    "        error_msg = (\"Softmax doesn't need to implement a gradient here, as it's\"\n",
    "                     \"only needed in CrossEntropyLoss, where we can simplify\"\n",
    "                     \"the gradient for the combined expression.\")\n",
    "        raise NotImplementedError(error_msg)\n",
    "\n",
    "\n",
    "class Relu(Module):\n",
    "\n",
    "    def forward(self, z: np.ndarray) -> np.ndarray:\n",
    "        self.input_cache = z\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        z = self.input_cache\n",
    "        return grad.reshape(z.shape) * np.where(z > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.W = Parameter(np.random.randn(out_features, in_features) * 0.01,\n",
    "                           name=\"W\")\n",
    "        self.b = Parameter(np.ones((out_features, 1)) * 0.01, name=\"b\")\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        assert len(x.shape) == 3, (\"x.shape should be (batch_size, input_size, 1)\"\n",
    "                                   \" but is {}.\".format(x.shape))\n",
    "        self.input_cache = x\n",
    "        z = self.W.data @ x + self.b.data\n",
    "        return z\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        x = self.input_cache\n",
    "        # remember that we have a batch dimension when transposing, i.e.,\n",
    "        # we need to use np.transpose instead of array.T\n",
    "        self.W.grad += np.sum(grad @ np.transpose(x, [0, 2, 1]), axis=0)\n",
    "        self.b.grad += np.sum(grad, axis=0)\n",
    "        return self.W.data.T @ grad\n",
    "\n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        return self.W, self.b\n",
    "\n",
    "\n",
    "class Sequential(Module):\n",
    "    \"\"\"A sequential container to stack modules.\n",
    "\n",
    "    Modules will be added to it in the order they are passed to the\n",
    "    constructor.\n",
    "\n",
    "    Example network with one hidden layer:\n",
    "    model = Sequential(\n",
    "                  Linear(5,10),\n",
    "                  ReLU(),\n",
    "                  Linear(10,10),\n",
    "                )\n",
    "    \"\"\"\n",
    "    def __init__(self, *args: List[Module]):\n",
    "        super().__init__()\n",
    "        self.modules = args\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        for module in self.modules:\n",
    "            x = module(x)  # equivalent to module.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        for module in reversed(self.modules):\n",
    "            grad = module.backward(grad)\n",
    "        return grad\n",
    "\n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        # iterate over modules and retrieve their parameters, iterate over\n",
    "        # parameters to flatten the list\n",
    "        return [param for module in self.modules\n",
    "                for param in module.parameters()]\n",
    "    \n",
    "    def train(self, mode: bool = True) -> 'Sequential':\n",
    "        \"\"\"Set the train mode of the Sequential module and it's sub-modules.\n",
    "        \n",
    "        This only affects some modules, e.g., Dropout.\n",
    "        \n",
    "        Returns:\n",
    "            self.\n",
    "        \"\"\"\n",
    "        for module in self.modules:\n",
    "            module.train(mode)\n",
    "        return self\n",
    "\n",
    "\n",
    "def one_hot_encoding(y: np.ndarray, num_classes: int) -> np.ndarray:\n",
    "    \"\"\"Convert integer labels to one hot encoding.\n",
    "\n",
    "    Example: y=[1, 2] --> [[0, 1, 0], [0, 0, 2]]\n",
    "    \"\"\"\n",
    "    encoded = np.zeros(y.shape + (num_classes,))\n",
    "    encoded[np.arange(len(y)), y] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"The base class for optimizers.\n",
    "\n",
    "    All optimizers must implement a step() method that updates the parameters.\n",
    "    The general optimization loop then looks like this:\n",
    "\n",
    "    for inputs, targets in dataset:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    `zero_grad` initializes the gradients of the parameters to zero. This\n",
    "    allows to accumulate gradients (instead of replacing it) during\n",
    "    backpropagation, which is e.g. useful for skip connections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params: Iterable[Parameter]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            params: The parameters to be optimized.\n",
    "        \"\"\"\n",
    "        self._params = params\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"Update the parameters.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        \"\"\"Clear the gradients of all optimized parameters.\"\"\"\n",
    "        for param in self._params:\n",
    "            assert isinstance(param, Parameter)\n",
    "            param.grad = np.zeros_like(param.data)\n",
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    \"\"\"Stochastic Gradient Descent (SGD) optimizer with optional Momentum.\"\"\"\n",
    "\n",
    "    def __init__(self, params: Iterable[Parameter], lr: float,\n",
    "                 momentum: Optional[float] = None):\n",
    "        super().__init__(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        if momentum:\n",
    "            for param in self._params:\n",
    "                param.state_dict[\"momentum\"] = np.zeros_like(param.data)\n",
    "\n",
    "    def step(self):\n",
    "        for p in self._params:\n",
    "            if self.momentum:\n",
    "                # update the momentum\n",
    "                p.state_dict[\"momentum\"] *= self.momentum\n",
    "                p.state_dict[\"momentum\"] -= self.lr * p.grad\n",
    "                # update the parameter\n",
    "                p.data += p.state_dict[\"momentum\"]\n",
    "            else:\n",
    "                p.data -= self.lr * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    \"\"\"Compute the cross entropy.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def forward(self, a: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute the cross entropy, mean over batch size.\"\"\"\n",
    "        a = self.softmax(a)\n",
    "        self.input_cache = a, y\n",
    "        # compute the mean over the batch\n",
    "        return -np.sum(np.log(a[y == 1])) / len(a)\n",
    "\n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        # we introduce the argument _ here, to have a unified interface with\n",
    "        # other Module objects. This simplifies code for gradient checking. \n",
    "        # We don't need this arg.\n",
    "        a, y = self.input_cache\n",
    "        grad = (a - y) / len(a)\n",
    "\n",
    "        # We have to recreate the batch dimension\n",
    "        grad = np.expand_dims(grad, -1)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, predictions, y_is_onehot: bool = False) -> float:\n",
    "    y_predicted = np.argmax(predictions, axis=-1)\n",
    "    y = np.argmax(y, axis=-1)\n",
    "    return np.sum(np.equal(y_predicted, y)) / len(y)\n",
    "\n",
    "\n",
    "def evaluate(data, labels, model, loss_fn, batch_size):\n",
    "    predictions = []\n",
    "    eval_cost = 0.\n",
    "    data_batched = minibatched(data, batch_size)\n",
    "    labels_batched = minibatched(labels, batch_size)\n",
    "\n",
    "    for x, y in zip(data_batched, labels_batched):\n",
    "        # note that when using cross entropy loss, the softmax is included in the\n",
    "        # loss and we'd need to apply it manually here to obtain the output as probabilities.\n",
    "        # However, softmax only rescales the outputs and doesn't change the argmax,\n",
    "        # so we'll skip this here, as we're only interested in the class prediction.\n",
    "        h_1 = np.squeeze(model(x))\n",
    "        predictions.append(h_1)\n",
    "        eval_cost += loss_fn(h_1, y)\n",
    "    predictions = np.array(predictions).reshape(-1, 10)\n",
    "    eval_accuracy = accuracy(y_val, predictions, False)\n",
    "    return eval_accuracy, eval_cost\n",
    "\n",
    "\n",
    "def train(model, loss_fn, optimizer, x_train, y_train, x_val, y_val,\n",
    "          num_epochs, batch_size, scheduler=None):\n",
    "    train_costs, train_accuracies = np.zeros(num_epochs), np.zeros(num_epochs)\n",
    "    eval_costs, eval_accuracies = np.zeros(num_epochs), np.zeros(num_epochs)\n",
    "    ix = np.arange(len(x_train))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {} / {}:\".format(epoch + 1, num_epochs))\n",
    "        print(\"LR---> \",optimizer.lr)\n",
    "        training_predictions = []\n",
    "        \n",
    "        np.random.shuffle(ix)\n",
    "        x_train_batched = minibatched(x_train[ix], batch_size)\n",
    "        y_train_batched = minibatched(y_train[ix], batch_size)\n",
    "        \n",
    "        # train for one epoch\n",
    "        model.train()\n",
    "        for x_batch, y_batch in zip(x_train_batched, y_train_batched):\n",
    "            optimizer.zero_grad()\n",
    "            y_batch_predicted = model(x_batch)\n",
    "            h_1 = np.squeeze(y_batch_predicted)\n",
    "            training_predictions.append(h_1)\n",
    "            loss = loss_fn(h_1, y_batch)\n",
    "            grad = loss_fn.backward()\n",
    "            model.backward(grad)\n",
    "            optimizer.step()\n",
    "            train_costs[epoch] += loss\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        model.eval()\n",
    "       \n",
    "        training_predictions = np.array(training_predictions).reshape(-1, 10)\n",
    "        train_accuracies[epoch] = accuracy(y_train[ix], training_predictions, False)\n",
    "        print(\"  Training Accuracy: {:.4f}\".format(train_accuracies[epoch]))\n",
    "        print(\"  Training Cost: {:.4f}\".format(train_costs[epoch]))\n",
    "        eval_accuracies[epoch], eval_costs[epoch] = evaluate(x_val, y_val, model, loss_fn, batch_size)\n",
    "        print(\"  Eval Accuracy: {:.4f}\".format(eval_accuracies[epoch]))\n",
    "    return train_costs, train_accuracies, eval_costs, eval_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    \"\"\"Loads the data, returns training_data, validation_data, test_data.\"\"\"\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin1')\n",
    "\n",
    "\n",
    "def minibatched(data: np.ndarray, batch_size: int) -> List[np.ndarray]:\n",
    "    assert len(data) % batch_size == 0, (\"Data length {} is not multiple of batch size {}\"\n",
    "                                         .format(len(data), batch_size))\n",
    "    return data.reshape(-1, batch_size, *data.shape[1:])\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_mnist_data()\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_val = np.expand_dims(x_val, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = one_hot_encoding(y_train, num_classes)\n",
    "y_val = one_hot_encoding(y_val, num_classes)\n",
    "y_test = one_hot_encoding(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adam'></a>\n",
    "### Adam\n",
    "**Implement the step function** of the adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-08):\n",
    "        super().__init__(params)\n",
    "        # we stick to the pytorch API, the variable names corresponding\n",
    "        # to the DL book are given in the comments\n",
    "        self.lr = lr  # lr is called epsilon in the DL book\n",
    "        self.betas = betas  # betas are called rho in the DL book\n",
    "        self.eps = eps  # eps is called delta in the DL book\n",
    "        self.t = 0\n",
    "        for param in self._params:\n",
    "            # first order moment variables, called m in the paper\n",
    "            param.state_dict[\"s\"] = np.zeros_like(param.data)\n",
    "            # second order moment variables, called v in the paper\n",
    "            param.state_dict[\"r\"] = np.zeros_like(param.data)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"Update the parameters and decaying averages of past gradients.\"\"\"\n",
    "        # START TODO ################\n",
    "        self.t += 1\n",
    "        for param in self._params:\n",
    "            # first order moment variables, called m in the paper\n",
    "            s = param.state_dict[\"s\"]\n",
    "            param.state_dict[\"s\"] = self.betas[0]*s + (1-self.betas[0]) * param.grad\n",
    "            r = param.state_dict[\"r\"]\n",
    "            param.state_dict[\"r\"] = self.betas[1]*r + (1-self.betas[1]) * param.grad * param.grad\n",
    "            # second order moment variables, called v in the paper\n",
    "            s_hat = s/(1-self.betas[0]**self.t)\n",
    "            r_hat = r/(1-self.betas[1]**self.t)\n",
    "            delta_theta = -(self.lr*s_hat)/ (self.eps + np.sqrt(r_hat))\n",
    "            param.data += delta_theta\n",
    "        # END TODO###################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare: Adam vs SGD vs SGD with Momentum\n",
    "\n",
    "**Train three models** (30 hidden units, relu) for 10 epochs, one with *Adam*, one with *SGD* and one with *SGD with momentum*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD without momentum------------->\n",
      "Epoch 1 / 10:\n",
      "LR--->  0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7ac053062567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0msgd_cst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msgd_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msgdVal_cst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msgdVal_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SGD with momentum------------->\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-d4305bb034ac>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_fn, optimizer, x_train, y_train, x_val, y_val, num_epochs, batch_size, scheduler)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtrain_costs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2f3ca71d0bc9>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2f3ca71d0bc9>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# remember that we have a batch dimension when transposing, i.e.,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# we need to use np.transpose instead of array.T\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "linear_units = 30\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "sgd_learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "adam_learning_rate = 0.01\n",
    "\n",
    "# START TODO ################\n",
    "\n",
    "print(\"SGD without momentum------------->\")\n",
    "model = Sequential(Linear(784,linear_units), Relu(), Linear(linear_units,10))\n",
    "params = model.parameters()\n",
    "optim = SGD(params, sgd_learning_rate)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "sgd_cst,sgd_acc,sgdVal_cst,sgdVal_acc=train(model, loss_fn, optim, x_train, y_train, x_val, y_val, num_epochs, batch_size);\n",
    "\n",
    "print(\"SGD with momentum------------->\")\n",
    "model = Sequential(Linear(784,linear_units), Relu(), Linear(linear_units,10))\n",
    "params = model.parameters()\n",
    "optim = SGD(params, sgd_learning_rate, momentum)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "sgdm_cst,sgdm_acc,sgdmVal_cst,sgdmVal_acc=train(model, loss_fn, optim, x_train, y_train, x_val, y_val, num_epochs, batch_size);\n",
    "\n",
    "print(\"Optimization with Adam------------->\")\n",
    "model = Sequential(Linear(784,linear_units), Relu(), Linear(linear_units,10))\n",
    "params = model.parameters()\n",
    "optim = Adam(params, adam_learning_rate)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "ad_cst,ad_acc,adVal_cst,adVal_acc=train(model, loss_fn, optim, x_train, y_train, x_val, y_val, num_epochs, batch_size);\n",
    "# END TODO###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create two plots**, one for the training loss curves and one for the training accuracies curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "\n",
    "# START TODO ################\n",
    "\n",
    "# END TODO###################D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Schedules\n",
    "\n",
    "Decreasing the learning rate can improve performance of the model.\n",
    "\n",
    "Pytorch implements learning rate schedules as wrappers for the optimizer and requires the user to call scheduler.step() after each epoch. (We've already done this for you in the training loop above)\n",
    "\n",
    "**Implement the learning rate scheduler** `PieceWiseConstantLR` and `CosineAnnealingLR`. You can use the provided `LambdaLR` class for this, which works analogously to the pytorch [LambdaLR](https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.LambdaLR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR:\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, lr_lambda: Callable[[int], float]):\n",
    "        \"\"\"Sets the learning rate to the initial lr times a given function.\n",
    "\n",
    "        Args:\n",
    "            optimizer: The optimzier to wrap.\n",
    "            lr_lambda: A function that takes the current epoch as an argument\n",
    "                and returns the corresponding learning rate.\n",
    "        \"\"\"\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "        self.last_epoch = 0\n",
    "        self.initial_lr = np.copy(optimizer.lr)\n",
    "        self.lr_lambda = lr_lambda\n",
    "        print(\"LR initial======\", self.initial_lr)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"To be called after each epoch. Update optimizer.lr\"\"\"\n",
    "        self.last_epoch += 1\n",
    "        self.optimizer.lr = self.lr_lambda(self.last_epoch)\n",
    "        print(\"SCHEDULED LR-------\",self.optimizer.lr)\n",
    "\n",
    "\n",
    "class PiecewiseConstantLR(LambdaLR):\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, epochs: List[int],\n",
    "                 learning_rates: List[float]):\n",
    "        \"\"\"Set learning rate as piecewise constant steps.\n",
    "\n",
    "        This class inherits from LambdaLR and implements the lambda\n",
    "        function that maps the current epoch to the learning rate\n",
    "        according to epochs.\n",
    "        \n",
    "        optimizer: The optimizer to wrap\n",
    "        \"\"\"\n",
    "        def lr_lambda(num_epo):\n",
    "            i = 0\n",
    "            for epo in epochs:\n",
    "                if num_epo < epo:\n",
    "                    return learning_rates[i]                \n",
    "                i+=1\n",
    "            return learning_rates[-1]\n",
    "        \n",
    "        super().__init__(optimizer,lr_lambda)\n",
    "        # START TODO ################\n",
    "        #raise NotImplementedError\n",
    "    \n",
    "\n",
    "        # End TODO ################\n",
    "        \n",
    "        \n",
    "class CosineAnnealingLR(LambdaLR):\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, T_max: int):\n",
    "        \"\"\"Set learning rate as a cosine decay.\n",
    "\n",
    "        This class inherits from LambdaLR and implements the lambda\n",
    "        function that maps the current epoch to the learning rate\n",
    "        according to epochs.\n",
    "        \n",
    "        optimizer: The optimizer to wrap\n",
    "        T_max:  Maximum number of epochs.\n",
    "        \"\"\"\n",
    "        # START TODO ################\n",
    "        #raise NotImplementedError\n",
    "        def lr_lambda(k):\n",
    "            return (0.5*(1+np.cos((k/T_max)*np.pi))*self.initial_lr)\n",
    "             \n",
    "        super().__init__(optimizer,lr_lambda)              \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify your implementation, **plot the learning rate schedules**, with the number of epochs on the x-axis and the learning rate on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR initial====== 0.01\n",
      "Epoch 1 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULED LR------- 0.009996145181203616\n",
      "  Training Accuracy: 0.8912\n",
      "  Training Cost: 348.5335\n",
      "  Eval Accuracy: 0.9426\n",
      "Epoch 2 / 80:\n",
      "LR--->  0.009996145181203616\n",
      "SCHEDULED LR------- 0.00998458666866564\n",
      "  Training Accuracy: 0.9418\n",
      "  Training Cost: 194.0480\n",
      "  Eval Accuracy: 0.9431\n",
      "Epoch 3 / 80:\n",
      "LR--->  0.00998458666866564\n",
      "SCHEDULED LR------- 0.009965342284774633\n",
      "  Training Accuracy: 0.9505\n",
      "  Training Cost: 164.6236\n",
      "  Eval Accuracy: 0.9529\n",
      "Epoch 4 / 80:\n",
      "LR--->  0.009965342284774633\n",
      "SCHEDULED LR------- 0.009938441702975689\n",
      "  Training Accuracy: 0.9552\n",
      "  Training Cost: 152.0284\n",
      "  Eval Accuracy: 0.9495\n",
      "Epoch 5 / 80:\n",
      "LR--->  0.009938441702975689\n",
      "SCHEDULED LR------- 0.009903926402016152\n",
      "  Training Accuracy: 0.9592\n",
      "  Training Cost: 137.0824\n",
      "  Eval Accuracy: 0.9503\n",
      "Epoch 6 / 80:\n",
      "LR--->  0.009903926402016152\n",
      "SCHEDULED LR------- 0.009861849601988383\n",
      "  Training Accuracy: 0.9614\n",
      "  Training Cost: 133.6105\n",
      "  Eval Accuracy: 0.9554\n",
      "Epoch 7 / 80:\n",
      "LR--->  0.009861849601988383\n",
      "SCHEDULED LR------- 0.009812276182268235\n",
      "  Training Accuracy: 0.9624\n",
      "  Training Cost: 126.3439\n",
      "  Eval Accuracy: 0.9573\n",
      "Epoch 8 / 80:\n",
      "LR--->  0.009812276182268235\n",
      "SCHEDULED LR------- 0.009755282581475769\n",
      "  Training Accuracy: 0.9649\n",
      "  Training Cost: 118.2823\n",
      "  Eval Accuracy: 0.9561\n",
      "Epoch 9 / 80:\n",
      "LR--->  0.009755282581475769\n",
      "SCHEDULED LR------- 0.00969095667961242\n",
      "  Training Accuracy: 0.9653\n",
      "  Training Cost: 114.5244\n",
      "  Eval Accuracy: 0.9576\n",
      "Epoch 10 / 80:\n",
      "LR--->  0.00969095667961242\n",
      "SCHEDULED LR------- 0.009619397662556433\n",
      "  Training Accuracy: 0.9665\n",
      "  Training Cost: 112.7183\n",
      "  Eval Accuracy: 0.9570\n",
      "Epoch 11 / 80:\n",
      "LR--->  0.009619397662556433\n",
      "SCHEDULED LR------- 0.009540715869125407\n",
      "  Training Accuracy: 0.9673\n",
      "  Training Cost: 108.3345\n",
      "  Eval Accuracy: 0.9503\n",
      "Epoch 12 / 80:\n",
      "LR--->  0.009540715869125407\n",
      "SCHEDULED LR------- 0.00945503262094184\n",
      "  Training Accuracy: 0.9687\n",
      "  Training Cost: 101.5204\n",
      "  Eval Accuracy: 0.9599\n",
      "Epoch 13 / 80:\n",
      "LR--->  0.00945503262094184\n",
      "SCHEDULED LR------- 0.009362480035363985\n",
      "  Training Accuracy: 0.9711\n",
      "  Training Cost: 95.7851\n",
      "  Eval Accuracy: 0.9551\n",
      "Epoch 14 / 80:\n",
      "LR--->  0.009362480035363985\n",
      "SCHEDULED LR------- 0.009263200821770462\n",
      "  Training Accuracy: 0.9713\n",
      "  Training Cost: 96.4731\n",
      "  Eval Accuracy: 0.9512\n",
      "Epoch 15 / 80:\n",
      "LR--->  0.009263200821770462\n",
      "SCHEDULED LR------- 0.009157348061512726\n",
      "  Training Accuracy: 0.9718\n",
      "  Training Cost: 96.2225\n",
      "  Eval Accuracy: 0.9571\n",
      "Epoch 16 / 80:\n",
      "LR--->  0.009157348061512726\n",
      "SCHEDULED LR------- 0.009045084971874737\n",
      "  Training Accuracy: 0.9747\n",
      "  Training Cost: 85.5267\n",
      "  Eval Accuracy: 0.9525\n",
      "Epoch 17 / 80:\n",
      "LR--->  0.009045084971874737\n",
      "SCHEDULED LR------- 0.008926584654403725\n",
      "  Training Accuracy: 0.9744\n",
      "  Training Cost: 85.7676\n",
      "  Eval Accuracy: 0.9517\n",
      "Epoch 18 / 80:\n",
      "LR--->  0.008926584654403725\n",
      "SCHEDULED LR------- 0.008802029828000156\n",
      "  Training Accuracy: 0.9736\n",
      "  Training Cost: 87.5873\n",
      "  Eval Accuracy: 0.9588\n",
      "Epoch 19 / 80:\n",
      "LR--->  0.008802029828000156\n",
      "SCHEDULED LR------- 0.008671612547178428\n",
      "  Training Accuracy: 0.9764\n",
      "  Training Cost: 75.8698\n",
      "  Eval Accuracy: 0.9554\n",
      "Epoch 20 / 80:\n",
      "LR--->  0.008671612547178428\n",
      "SCHEDULED LR------- 0.008535533905932738\n",
      "  Training Accuracy: 0.9763\n",
      "  Training Cost: 77.1139\n",
      "  Eval Accuracy: 0.9580\n",
      "Epoch 21 / 80:\n",
      "LR--->  0.008535533905932738\n",
      "SCHEDULED LR------- 0.00839400372766471\n",
      "  Training Accuracy: 0.9768\n",
      "  Training Cost: 75.1337\n",
      "  Eval Accuracy: 0.9599\n",
      "Epoch 22 / 80:\n",
      "LR--->  0.00839400372766471\n",
      "SCHEDULED LR------- 0.00824724024165092\n",
      "  Training Accuracy: 0.9777\n",
      "  Training Cost: 73.5981\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 23 / 80:\n",
      "LR--->  0.00824724024165092\n",
      "SCHEDULED LR------- 0.00809546974654917\n",
      "  Training Accuracy: 0.9788\n",
      "  Training Cost: 68.8296\n",
      "  Eval Accuracy: 0.9570\n",
      "Epoch 24 / 80:\n",
      "LR--->  0.00809546974654917\n",
      "SCHEDULED LR------- 0.007938926261462366\n",
      "  Training Accuracy: 0.9793\n",
      "  Training Cost: 68.7155\n",
      "  Eval Accuracy: 0.9566\n",
      "Epoch 25 / 80:\n",
      "LR--->  0.007938926261462366\n",
      "SCHEDULED LR------- 0.007777851165098011\n",
      "  Training Accuracy: 0.9805\n",
      "  Training Cost: 64.5602\n",
      "  Eval Accuracy: 0.9583\n",
      "Epoch 26 / 80:\n",
      "LR--->  0.007777851165098011\n",
      "SCHEDULED LR------- 0.0076124928235797445\n",
      "  Training Accuracy: 0.9810\n",
      "  Training Cost: 59.8507\n",
      "  Eval Accuracy: 0.9586\n",
      "Epoch 27 / 80:\n",
      "LR--->  0.0076124928235797445\n",
      "SCHEDULED LR------- 0.007443106207484776\n",
      "  Training Accuracy: 0.9801\n",
      "  Training Cost: 66.4518\n",
      "  Eval Accuracy: 0.9561\n",
      "Epoch 28 / 80:\n",
      "LR--->  0.007443106207484776\n",
      "SCHEDULED LR------- 0.007269952498697734\n",
      "  Training Accuracy: 0.9822\n",
      "  Training Cost: 55.7201\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 29 / 80:\n",
      "LR--->  0.007269952498697734\n",
      "SCHEDULED LR------- 0.007093298687687141\n",
      "  Training Accuracy: 0.9830\n",
      "  Training Cost: 53.6008\n",
      "  Eval Accuracy: 0.9592\n",
      "Epoch 30 / 80:\n",
      "LR--->  0.007093298687687141\n",
      "SCHEDULED LR------- 0.00691341716182545\n",
      "  Training Accuracy: 0.9842\n",
      "  Training Cost: 50.6465\n",
      "  Eval Accuracy: 0.9576\n",
      "Epoch 31 / 80:\n",
      "LR--->  0.00691341716182545\n",
      "SCHEDULED LR------- 0.006730585285387465\n",
      "  Training Accuracy: 0.9852\n",
      "  Training Cost: 45.6431\n",
      "  Eval Accuracy: 0.9612\n",
      "Epoch 32 / 80:\n",
      "LR--->  0.006730585285387465\n",
      "SCHEDULED LR------- 0.006545084971874737\n",
      "  Training Accuracy: 0.9850\n",
      "  Training Cost: 45.9957\n",
      "  Eval Accuracy: 0.9585\n",
      "Epoch 33 / 80:\n",
      "LR--->  0.006545084971874737\n",
      "SCHEDULED LR------- 0.006357202249325371\n",
      "  Training Accuracy: 0.9866\n",
      "  Training Cost: 42.5227\n",
      "  Eval Accuracy: 0.9623\n",
      "Epoch 34 / 80:\n",
      "LR--->  0.006357202249325371\n",
      "SCHEDULED LR------- 0.0061672268192795275\n",
      "  Training Accuracy: 0.9872\n",
      "  Training Cost: 40.0018\n",
      "  Eval Accuracy: 0.9583\n",
      "Epoch 35 / 80:\n",
      "LR--->  0.0061672268192795275\n",
      "SCHEDULED LR------- 0.005975451610080642\n",
      "  Training Accuracy: 0.9866\n",
      "  Training Cost: 40.0165\n",
      "  Eval Accuracy: 0.9578\n",
      "Epoch 36 / 80:\n",
      "LR--->  0.005975451610080642\n",
      "SCHEDULED LR------- 0.0057821723252011546\n",
      "  Training Accuracy: 0.9885\n",
      "  Training Cost: 35.8435\n",
      "  Eval Accuracy: 0.9580\n",
      "Epoch 37 / 80:\n",
      "LR--->  0.0057821723252011546\n",
      "SCHEDULED LR------- 0.0055876869872891885\n",
      "  Training Accuracy: 0.9884\n",
      "  Training Cost: 36.1018\n",
      "  Eval Accuracy: 0.9605\n",
      "Epoch 38 / 80:\n",
      "LR--->  0.0055876869872891885\n",
      "SCHEDULED LR------- 0.0053922954786392256\n",
      "  Training Accuracy: 0.9884\n",
      "  Training Cost: 35.9819\n",
      "  Eval Accuracy: 0.9576\n",
      "Epoch 39 / 80:\n",
      "LR--->  0.0053922954786392256\n",
      "SCHEDULED LR------- 0.005196299078795343\n",
      "  Training Accuracy: 0.9906\n",
      "  Training Cost: 29.8102\n",
      "  Eval Accuracy: 0.9588\n",
      "Epoch 40 / 80:\n",
      "LR--->  0.005196299078795343\n",
      "SCHEDULED LR------- 0.005\n",
      "  Training Accuracy: 0.9900\n",
      "  Training Cost: 30.0498\n",
      "  Eval Accuracy: 0.9572\n",
      "Epoch 41 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULED LR------- 0.004803700921204659\n",
      "  Training Accuracy: 0.9912\n",
      "  Training Cost: 25.6343\n",
      "  Eval Accuracy: 0.9605\n",
      "Epoch 42 / 80:\n",
      "LR--->  0.004803700921204659\n",
      "SCHEDULED LR------- 0.004607704521360776\n",
      "  Training Accuracy: 0.9918\n",
      "  Training Cost: 25.6376\n",
      "  Eval Accuracy: 0.9585\n",
      "Epoch 43 / 80:\n",
      "LR--->  0.004607704521360776\n",
      "SCHEDULED LR------- 0.004412313012710813\n",
      "  Training Accuracy: 0.9921\n",
      "  Training Cost: 23.4758\n",
      "  Eval Accuracy: 0.9590\n",
      "Epoch 44 / 80:\n",
      "LR--->  0.004412313012710813\n",
      "SCHEDULED LR------- 0.004217827674798845\n",
      "  Training Accuracy: 0.9930\n",
      "  Training Cost: 21.0327\n",
      "  Eval Accuracy: 0.9599\n",
      "Epoch 45 / 80:\n",
      "LR--->  0.004217827674798845\n",
      "SCHEDULED LR------- 0.004024548389919359\n",
      "  Training Accuracy: 0.9939\n",
      "  Training Cost: 18.5467\n",
      "  Eval Accuracy: 0.9572\n",
      "Epoch 46 / 80:\n",
      "LR--->  0.004024548389919359\n",
      "SCHEDULED LR------- 0.003832773180720475\n",
      "  Training Accuracy: 0.9938\n",
      "  Training Cost: 18.2447\n",
      "  Eval Accuracy: 0.9603\n",
      "Epoch 47 / 80:\n",
      "LR--->  0.003832773180720475\n",
      "SCHEDULED LR------- 0.003642797750674629\n",
      "  Training Accuracy: 0.9940\n",
      "  Training Cost: 17.5862\n",
      "  Eval Accuracy: 0.9615\n",
      "Epoch 48 / 80:\n",
      "LR--->  0.003642797750674629\n",
      "SCHEDULED LR------- 0.003454915028125263\n",
      "  Training Accuracy: 0.9949\n",
      "  Training Cost: 15.2736\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 49 / 80:\n",
      "LR--->  0.003454915028125263\n",
      "SCHEDULED LR------- 0.003269414714612534\n",
      "  Training Accuracy: 0.9956\n",
      "  Training Cost: 13.4955\n",
      "  Eval Accuracy: 0.9618\n",
      "Epoch 50 / 80:\n",
      "LR--->  0.003269414714612534\n",
      "SCHEDULED LR------- 0.0030865828381745515\n",
      "  Training Accuracy: 0.9957\n",
      "  Training Cost: 13.3188\n",
      "  Eval Accuracy: 0.9599\n",
      "Epoch 51 / 80:\n",
      "LR--->  0.0030865828381745515\n",
      "SCHEDULED LR------- 0.002906701312312861\n",
      "  Training Accuracy: 0.9967\n",
      "  Training Cost: 10.8119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval Accuracy: 0.9590\n",
      "Epoch 52 / 80:\n",
      "LR--->  0.002906701312312861\n",
      "SCHEDULED LR------- 0.0027300475013022664\n",
      "  Training Accuracy: 0.9969\n",
      "  Training Cost: 10.3791\n",
      "  Eval Accuracy: 0.9598\n",
      "Epoch 53 / 80:\n",
      "LR--->  0.0027300475013022664\n",
      "SCHEDULED LR------- 0.002556893792515227\n",
      "  Training Accuracy: 0.9971\n",
      "  Training Cost: 9.6491\n",
      "  Eval Accuracy: 0.9596\n",
      "Epoch 54 / 80:\n",
      "LR--->  0.002556893792515227\n",
      "SCHEDULED LR------- 0.002387507176420256\n",
      "  Training Accuracy: 0.9975\n",
      "  Training Cost: 8.3019\n",
      "  Eval Accuracy: 0.9617\n",
      "Epoch 55 / 80:\n",
      "LR--->  0.002387507176420256\n",
      "SCHEDULED LR------- 0.00222214883490199\n",
      "  Training Accuracy: 0.9977\n",
      "  Training Cost: 7.6498\n",
      "  Eval Accuracy: 0.9599\n",
      "Epoch 56 / 80:\n",
      "LR--->  0.00222214883490199\n",
      "SCHEDULED LR------- 0.0020610737385376348\n",
      "  Training Accuracy: 0.9984\n",
      "  Training Cost: 6.2537\n",
      "  Eval Accuracy: 0.9589\n",
      "Epoch 57 / 80:\n",
      "LR--->  0.0020610737385376348\n",
      "SCHEDULED LR------- 0.0019045302534508297\n",
      "  Training Accuracy: 0.9987\n",
      "  Training Cost: 5.5578\n",
      "  Eval Accuracy: 0.9588\n",
      "Epoch 58 / 80:\n",
      "LR--->  0.0019045302534508297\n",
      "SCHEDULED LR------- 0.0017527597583490823\n",
      "  Training Accuracy: 0.9985\n",
      "  Training Cost: 5.7849\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 59 / 80:\n",
      "LR--->  0.0017527597583490823\n",
      "SCHEDULED LR------- 0.0016059962723352905\n",
      "  Training Accuracy: 0.9987\n",
      "  Training Cost: 5.2298\n",
      "  Eval Accuracy: 0.9586\n",
      "Epoch 60 / 80:\n",
      "LR--->  0.0016059962723352905\n",
      "SCHEDULED LR------- 0.0014644660940672626\n",
      "  Training Accuracy: 0.9988\n",
      "  Training Cost: 4.6953\n",
      "  Eval Accuracy: 0.9594\n",
      "Epoch 61 / 80:\n",
      "LR--->  0.0014644660940672626\n",
      "SCHEDULED LR------- 0.0013283874528215733\n",
      "  Training Accuracy: 0.9990\n",
      "  Training Cost: 4.3312\n",
      "  Eval Accuracy: 0.9596\n",
      "Epoch 62 / 80:\n",
      "LR--->  0.0013283874528215733\n",
      "SCHEDULED LR------- 0.0011979701719998454\n",
      "  Training Accuracy: 0.9991\n",
      "  Training Cost: 3.9040\n",
      "  Eval Accuracy: 0.9596\n",
      "Epoch 63 / 80:\n",
      "LR--->  0.0011979701719998454\n",
      "SCHEDULED LR------- 0.0010734153455962765\n",
      "  Training Accuracy: 0.9991\n",
      "  Training Cost: 3.7202\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 64 / 80:\n",
      "LR--->  0.0010734153455962765\n",
      "SCHEDULED LR------- 0.0009549150281252633\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 3.2873\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 65 / 80:\n",
      "LR--->  0.0009549150281252633\n",
      "SCHEDULED LR------- 0.0008426519384872733\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 3.1412\n",
      "  Eval Accuracy: 0.9593\n",
      "Epoch 66 / 80:\n",
      "LR--->  0.0008426519384872733\n",
      "SCHEDULED LR------- 0.0007367991782295391\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 3.0172\n",
      "  Eval Accuracy: 0.9595\n",
      "Epoch 67 / 80:\n",
      "LR--->  0.0007367991782295391\n",
      "SCHEDULED LR------- 0.0006375199646360141\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 2.8425\n",
      "  Eval Accuracy: 0.9588\n",
      "Epoch 68 / 80:\n",
      "LR--->  0.0006375199646360141\n",
      "SCHEDULED LR------- 0.0005449673790581611\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.6980\n",
      "  Eval Accuracy: 0.9587\n",
      "Epoch 69 / 80:\n",
      "LR--->  0.0005449673790581611\n",
      "SCHEDULED LR------- 0.0004592841308745932\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 2.6055\n",
      "  Eval Accuracy: 0.9586\n",
      "Epoch 70 / 80:\n",
      "LR--->  0.0004592841308745932\n",
      "SCHEDULED LR------- 0.0003806023374435663\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 2.4767\n",
      "  Eval Accuracy: 0.9588\n",
      "Epoch 71 / 80:\n",
      "LR--->  0.0003806023374435663\n",
      "SCHEDULED LR------- 0.00030904332038757975\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.3924\n",
      "  Eval Accuracy: 0.9590\n",
      "Epoch 72 / 80:\n",
      "LR--->  0.00030904332038757975\n",
      "SCHEDULED LR------- 0.00024471741852423234\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.3114\n",
      "  Eval Accuracy: 0.9581\n",
      "Epoch 73 / 80:\n",
      "LR--->  0.00024471741852423234\n",
      "SCHEDULED LR------- 0.00018772381773176416\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.2456\n",
      "  Eval Accuracy: 0.9580\n",
      "Epoch 74 / 80:\n",
      "LR--->  0.00018772381773176416\n",
      "SCHEDULED LR------- 0.0001381503980116172\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.1989\n",
      "  Eval Accuracy: 0.9581\n",
      "Epoch 75 / 80:\n",
      "LR--->  0.0001381503980116172\n",
      "SCHEDULED LR------- 9.607359798384785e-05\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.1530\n",
      "  Eval Accuracy: 0.9579\n",
      "Epoch 76 / 80:\n",
      "LR--->  9.607359798384785e-05\n",
      "SCHEDULED LR------- 6.15582970243117e-05\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.1215\n",
      "  Eval Accuracy: 0.9577\n",
      "Epoch 77 / 80:\n",
      "LR--->  6.15582970243117e-05\n",
      "SCHEDULED LR------- 3.465771522536854e-05\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.0972\n",
      "  Eval Accuracy: 0.9578\n",
      "Epoch 78 / 80:\n",
      "LR--->  3.465771522536854e-05\n",
      "SCHEDULED LR------- 1.541333133436018e-05\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.0783\n",
      "  Eval Accuracy: 0.9578\n",
      "Epoch 79 / 80:\n",
      "LR--->  1.541333133436018e-05\n",
      "SCHEDULED LR------- 3.854818796385496e-06\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.0671\n",
      "  Eval Accuracy: 0.9577\n",
      "Epoch 80 / 80:\n",
      "LR--->  3.854818796385496e-06\n",
      "SCHEDULED LR------- 0.0\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 2.0602\n",
      "  Eval Accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 80\n",
    "\n",
    "linear_units = 30\n",
    "batch_size = 50\n",
    "sgd_learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "adam_learning_rate = 0.01\n",
    "\n",
    "\n",
    "model = Sequential(Linear(784,linear_units), Relu(), Linear(linear_units,10))\n",
    "params = model.parameters()\n",
    "optim = Adam(params, adam_learning_rate)\n",
    "picewise_scheduler = PiecewiseConstantLR(optim, [10, 20, 40, 50], [0.01, 0.005, 0.001, 0.0001])\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "ad_cst,ad_acc,adVal_cst,adVal_acc=train(model, loss_fn, optim, x_train, y_train, x_val, y_val, num_epochs, batch_size, picewise_scheduler);\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential(Linear(784,linear_units), Relu(), Linear(linear_units,10))\n",
    "params = model.parameters()\n",
    "optim = Adam(params, adam_learning_rate)\n",
    "picewise_scheduler = CosineAnnealingLR(optim, num_epochs)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "ad_cst,ad_acc,adVal_cst,adVal_acc=train(model, loss_fn, optim, x_train, y_train, x_val, y_val, num_epochs, batch_size, picewise_scheduler);\n",
    "\n",
    "#optimizer = Adam([])\n",
    "#cosine_scheduler = CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "# START TODO ################\n",
    "# plot piecewise lr\n",
    "\n",
    "# plot cosine lr\n",
    "# End TODO ################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Feedback on Exercise 3.1\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "In this part of the exercise we will take a look multiple regularizers.\n",
    "\n",
    "### Dropout\n",
    "**Fill in the missing gaps** for the implementation of the dropout regularization (Chapter 7.12 in the DL book).\n",
    "During training, the dropout layer randomly sets the input tensor to 0 with probability p and scales the remaining values accordingly. During evaluation, the dropout layer returns the identity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Module):\n",
    "    \"\"\"Set input elements to zero during training with probability p.\"\"\"\n",
    "\n",
    "    def __init__(self, p : float = 0.5, fix_seed=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p: Probability of an element to be zeroed. Default: 0.5.\n",
    "            fix_seed: If true, we always use the same seed in the forward pass.\n",
    "                This is only needed for gradient checking and should only be\n",
    "                set True for gradient checking.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        # START TODO ################\n",
    "        self.scale = 1.0/(1.0-p)\n",
    "        # END TODO ################\n",
    "        self.fix_seed = fix_seed\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply dropout during training.\n",
    "        \n",
    "        Set values to zero with probability p during training\n",
    "        and scale them by 1/(1-p). Returns identidy during\n",
    "        evaluation mode (--> self.training = False).\n",
    "\n",
    "        Note: This layer should work with all kinds of input shapes.\n",
    "        \"\"\" \n",
    "        if not self.training:\n",
    "            return x\n",
    "        if self.fix_seed:  # we need this for gradient checking \n",
    "            np.random.seed(0)\n",
    "        # START TODO ################\n",
    "        self.mask = np.random.binomial(1, self.p, size = x.shape[0]) * self.scale\n",
    "        x = x * self.mask \n",
    "        return x\n",
    "        # END TODO ################\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        if not self.training:\n",
    "            raise ValueError(\"Model is set to evaluation mode.\")\n",
    "        # START TODO ################\n",
    "        d = grad * self.mask\n",
    "        return d\n",
    "        # END TODO ################\n",
    "\n",
    "\n",
    "# Check the gradient implementation\n",
    "x = np.random.rand(1, 1, 4, 4)\n",
    "Dropout(fix_seed=True).check_gradients((x,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1/L2 regularization\n",
    "**Implement $L_1$/$L_2$ regularization**. This is one of the rare cases where we differ from the pytorch API. The reason is that pytorch implements $L_2$ regularization in the optimizer but calles it `weight_decay` (which is actually a different operation if you're not using SGD).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'W'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ccd91b660172>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1Regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#l2.check_gradients_wrt_params((), 1e-6)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0ml1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_gradients_wrt_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b9096a5168c1>\u001b[0m in \u001b[0;36mcheck_gradients_wrt_params\u001b[1;34m(self, input_args, tolerance)\u001b[0m\n\u001b[0;32m    146\u001b[0m             error = scipy.optimize.check_grad(output_given_params,\n\u001b[0;32m    147\u001b[0m                                               \u001b[0mgrad_given_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                                               param_init)\n\u001b[0m\u001b[0;32m    149\u001b[0m             \u001b[0mnum_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_outputs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mcheck_grad\u001b[1;34m(func, grad, x0, *args, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m         raise ValueError(\"Unknown keyword arguments: %r\" %\n\u001b[0;32m    750\u001b[0m                          (list(kwargs.keys()),))\n\u001b[1;32m--> 751\u001b[1;33m     return sqrt(sum((grad(x0, *args) -\n\u001b[0m\u001b[0;32m    752\u001b[0m                      approx_fprime(x0, func, step, *args))**2))\n\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b9096a5168c1>\u001b[0m in \u001b[0;36mgrad_given_params\u001b[1;34m(new_param)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_zero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                 \u001b[1;31m# compute the gradient w.r.t. to param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-ccd91b660172>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# START TODO ################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# END TODO ################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'W'"
     ]
    }
   ],
   "source": [
    "class L1Regularization(Module):\n",
    "\n",
    "    def __init__(self, alpha: float, parameters: List[Parameter]):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.params = parameters\n",
    "    \n",
    "    def forward(self) -> np.ndarray:\n",
    "        # START TODO ################\n",
    "        \n",
    "        # END TODO ################\n",
    "\n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        # START TODO ################\n",
    "        \n",
    "        # END TODO ################\n",
    "        \n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        return self.params\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Check the gradient implementation. Here we can only check w.r.t. the parameters.\n",
    "params = [Parameter(np.random.rand(50, 1) * 0.1)]\n",
    "#l2 = L2Regularization(0.1, params)\n",
    "l1 = L1Regularization(0.1, params)\n",
    "#l2.check_gradients_wrt_params((), 1e-6)\n",
    "l1.check_gradients_wrt_params((), 1e-6)\n",
    "\n",
    "\n",
    "class RegularizedCrossEntropy(Module):\n",
    "    \"\"\"Combines Cross Entropy loss and Regularization loss by summing them.\"\"\"\n",
    "    \n",
    "    def __init__(self, regularization_loss: Module):\n",
    "        self.reg_loss = regularization_loss\n",
    "        self.cross_entropy = CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, a: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return self.cross_entropy(a, y) + self.reg_loss()\n",
    "        \n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        self.reg_loss.backward()  # this updates parameter gradients, no grad w.r.t input\n",
    "        return self.cross_entropy.backward()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the effect of regularization on the model parameters.\n",
    "We'll do that with **four trained models**:\n",
    "1. Without regularization. It's always a good idea to train your model without any regularization first. Not only to have a baseline but also to check if your model is able to overfit the training data. If it can't overfit, it's likely not powerful enough or there's an error in the implementation. \n",
    "2. With L2 regularization, alpha = 0.0001, on the weight parameters (not on the bias)\n",
    "3. With L1 regularization, alpha = 0.0001, on the weight parameters (not on the bias)\n",
    "4. With Dropout, drop_probability = 0.3 for the input, drop_probability = 0.5 for the hidden layers.\n",
    "\n",
    "*Note* that in this case L1/L2/Dropout lead to worse accuracies. This is due to the fact that we use only 30 linear units to keep training times short, which already imposes strong regularization. In practice, we would select a more powerful model. However, the small model still nicely exhibits the effect of regularization on the distribution of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.05\n",
    "momentum = 0.9\n",
    "linear_units = 30\n",
    "alpha_l1 = 0.0001\n",
    "alpha_l2 = 0.0001\n",
    "\n",
    "def build_model():\n",
    "    return Sequential(Linear(784, linear_units),\n",
    "                      Relu(),\n",
    "                      Linear(linear_units, 10))\n",
    "\n",
    "\n",
    "def build_model_dropout():\n",
    "    return Sequential(Dropout(0.3),\n",
    "                      Linear(784, linear_units),\n",
    "                      Relu(),\n",
    "                      Dropout(0.5),\n",
    "                      Linear(linear_units, 10))\n",
    "\n",
    "models = {}  # dict to store the trained models\n",
    "# let's save a model, which we won't train, to get the initial parameter distribution\n",
    "models[\"before_training\"] = build_model()\n",
    "\n",
    "# no regularization\n",
    "print(\"No regularization.\")\n",
    "models[\"no_reg\"] = build_model()\n",
    "params = [p for p in models[\"no_reg\"].parameters() if \"W\" in p.name]\n",
    "cross_entropy = CrossEntropyLoss()\n",
    "optimizer = SGD(models[\"no_reg\"].parameters(), lr=learning_rate, momentum=momentum)\n",
    "train(models[\"no_reg\"], cross_entropy, optimizer, x_train, y_train,\n",
    "      x_val, y_val, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# START TODO ################\n",
    "\n",
    "\n",
    "# L2 regularization\n",
    "print(\"L2 regularization.\")\n",
    "\n",
    "\n",
    "\n",
    "# L1 regularization\n",
    "print(\"L1 regularization.\")\n",
    "\n",
    "\n",
    "\n",
    "# dropout\n",
    "print(\"Dropout.\")\n",
    "\n",
    "\n",
    "# END TODO ################\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the parameter distribution of the four models by **plotting the histogram of their weight values from -1 to 1 with 100 bins**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "\n",
    "# End TODO ################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation increases model generalization by increasing the training set with fake data.\n",
    "\n",
    "**Question:** State *five effective operations* to generate fake data on the *MNIST dataset*. State *one operation* which doesn't make sense and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Another very popular technique in deep learning is *early stopping* (deeplearning book, section 7.8). \n",
    "\n",
    "![Figure 7.3 from the DeepLearningBook](learning-curve-dl-fig-7-3.png \"TEST\")\n",
    "\n",
    "**Questions:**\n",
    "How do the given loss curves (deep learning book, figure 7.3) relate to *early stopping*?\n",
    "Why is it a regularization technique? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Feedback on Exercise 3.2\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
